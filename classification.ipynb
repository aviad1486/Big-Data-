{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9afd174b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: xgboost in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: catboost in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: tabPFN in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.9)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.15.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (3.10.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (6.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: torch<3,>=2.1 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tabPFN) (2.6.0+cu118)\n",
      "Requirement already satisfied: scikit-learn<1.7,>=1.2.0 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tabPFN) (1.6.1)\n",
      "Requirement already satisfied: typing_extensions>=4.4.0 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tabPFN) (4.12.2)\n",
      "Requirement already satisfied: einops<0.9,>=0.2.0 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tabPFN) (0.8.1)\n",
      "Requirement already satisfied: huggingface-hub<1,>=0.0.1 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tabPFN) (0.29.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1,>=0.0.1->tabPFN) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1,>=0.0.1->tabPFN) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\aviad\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1,>=0.0.1->tabPFN) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1,>=0.0.1->tabPFN) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1,>=0.0.1->tabPFN) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1,>=0.0.1->tabPFN) (4.67.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn<1.7,>=1.2.0->tabPFN) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn<1.7,>=1.2.0->tabPFN) (3.5.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch<3,>=2.1->tabPFN) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch<3,>=2.1->tabPFN) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch<3,>=2.1->tabPFN) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch<3,>=2.1->tabPFN) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch<3,>=2.1->tabPFN) (1.3.0)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\aviad\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface-hub<1,>=0.0.1->tabPFN) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch<3,>=2.1->tabPFN) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (3.2.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from plotly->catboost) (1.29.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub<1,>=0.0.1->tabPFN) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub<1,>=0.0.1->tabPFN) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub<1,>=0.0.1->tabPFN) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aviad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub<1,>=0.0.1->tabPFN) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas xgboost catboost lightgbm tabPFN imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c3250",
   "metadata": {},
   "source": [
    "### 1: \n",
    "Importing the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccac877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc3ecb",
   "metadata": {},
   "source": [
    "### 2:\n",
    "load the data and declaring the dataframe and split the data to matrix X and vector Y (I'll do it later as a part of step 3)\n",
    "\n",
    "A dataset for classification task the output is the income column.\n",
    "32561 rows, 15 cols 6 numerical features.\n",
    " you can find the dataset here: https://www.kaggle.com/datasets/uciml/adult-census-income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f25656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15)\n",
      "age                int64\n",
      "workclass         object\n",
      "fnlwgt             int64\n",
      "education         object\n",
      "education.num      int64\n",
      "marital.status    object\n",
      "occupation        object\n",
      "relationship      object\n",
      "race              object\n",
      "sex               object\n",
      "capital.gain       int64\n",
      "capital.loss       int64\n",
      "hours.per.week     int64\n",
      "native.country    object\n",
      "income            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('adult.csv')\n",
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb52ce3",
   "metadata": {},
   "source": [
    "### 3:\n",
    "Creating a preprocessing function:\n",
    "* I decided to create sub functions first and call them from a 'main' function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4cbc1",
   "metadata": {},
   "source": [
    "A:  CHECKING FOR MISSING VALUES (THERE ISN'T MISSING VALUES) AND CATEGORICAL COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31240962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education.num     0\n",
       "marital.status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital.gain      0\n",
       "capital.loss      0\n",
       "hours.per.week    0\n",
       "native.country    0\n",
       "income            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15910795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df):\n",
    "    print(\"Checking for missing values:\")\n",
    "    print(df.isnull().sum())\n",
    "    # df = df.fillna()  THERE IS NO NULL VALUES ANYWAY SO WE DON'T NEED THAT (:\n",
    "    return df\n",
    "\n",
    "def drop_high_cardinality_categorical_features(X, threshold=5):\n",
    "    categorical_cols = X.select_dtypes(include='object').columns\n",
    "    high_card_cols = [col for col in categorical_cols if X[col].nunique() > threshold]\n",
    "    \n",
    "    print(f\"🧹 Dropping high-cardinality categorical columns: {high_card_cols}\")\n",
    "    X = X.drop(columns=high_card_cols)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def convert_categorical_to_dummies(X):\n",
    "    print(\"Converting categorical variables to dummy variables...\")\n",
    "    X = pd.get_dummies(X, drop_first=True) \n",
    "    print(f\"New shape after encoding: {X.shape}\")\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa15e813",
   "metadata": {},
   "source": [
    "B: REMOVING DUPLICATES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b0b101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_rows(X, y):\n",
    "    print(\"Initial number of rows:\", len(X))\n",
    "    \n",
    "    # Combine X and y to detect and drop duplicates together\n",
    "    df_combined = pd.concat([X, y], axis=1)\n",
    "    df_combined_no_duplicates = df_combined.drop_duplicates()\n",
    "\n",
    "    # Separate X and y again\n",
    "    X_cleaned = df_combined_no_duplicates.drop(columns=[y.name])\n",
    "    y_cleaned = df_combined_no_duplicates[y.name]\n",
    "\n",
    "    print(\"Number of rows after removing duplicates:\", len(X_cleaned))\n",
    "    return X_cleaned, y_cleaned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51437e93",
   "metadata": {},
   "source": [
    "C: SPLITTING FOR TRAIN/TEST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90e5e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    print(\"Splitting data into training and testing sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    print(f\"Training set size: {X_train.shape}\")\n",
    "    print(f\"Testing set size: {X_test.shape}\")\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231915d5",
   "metadata": {},
   "source": [
    "D: STANDARDIZE THE DATA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b835dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_features(X_train, X_test):\n",
    "    print(\"Standardizing feature columns...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print(\"Standardization complete.\")\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4856cd23",
   "metadata": {},
   "source": [
    "E: Handle Class Imbalance:\n",
    "I used Chat GPT in this part for helping me plotting the graph\n",
    "* There was a need to balance the data and I chose to oversampling the minority class because it's simple and avoids losing data.\n",
    "* The advantages of this method are: preventing the model from being biased toward the majority class, improving recall and F1-score for the minority class, and it works well on decision tree and random forest which I will use later in this project.\n",
    "* We use this method when the dataset is small, when we want to avoid losing information, and when the minority class have high importance for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cd1773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_class_imbalance(y):\n",
    "    print(\"Class distribution:\")\n",
    "    print(y.value_counts())\n",
    "    print(\"\\nPercentage distribution:\")\n",
    "    print(round(y.value_counts(normalize=True) * 100, 2))\n",
    "    \n",
    "    # Plot class distribution\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    y.value_counts().plot(kind='bar', color='skyblue')\n",
    "    plt.title('Target Class Distribution')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0956688e",
   "metadata": {},
   "source": [
    "F: MAKE THE FUNCTION CALLS BY THE ORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f45e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_classification_pipeline(df, target_column):\n",
    "    # Step 1: Split to X and y\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Step 2: Handle missing values in X\n",
    "    X = check_missing_values(X)\n",
    "\n",
    "    # Step 3: Remove high-cardinality categorical columns from X\n",
    "    X = drop_high_cardinality_categorical_features(X)\n",
    "\n",
    "    # Step 4: Convert categorical columns in X to dummy variables\n",
    "    X = convert_categorical_to_dummies(X)\n",
    "\n",
    "    # Step 5: Remove duplicate rows from X and y \n",
    "    X, y = remove_duplicate_rows(X, y)\n",
    "\n",
    "    # Step 6: Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Step 7: Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Step 8: Analyze class imbalance\n",
    "    analyze_class_imbalance(y) \n",
    "\n",
    "    # Step 9: Imbalance detected: Oversample the minority class in the training set and stardize again\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Step 10: Report final class distribution\n",
    "    print(\"\\nFinal class distribution in training set:\")\n",
    "    print(y_train.value_counts(normalize=True) * 100)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3167def9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing values:\n",
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education.num     0\n",
      "marital.status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital.gain      0\n",
      "capital.loss      0\n",
      "hours.per.week    0\n",
      "native.country    0\n",
      "dtype: int64\n",
      "🧹 Dropping high-cardinality categorical columns: ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'native.country']\n",
      "Converting categorical variables to dummy variables...\n",
      "New shape after encoding: (32561, 11)\n",
      "Initial number of rows: 32561\n",
      "Number of rows after removing duplicates: 32376\n",
      "Class distribution:\n",
      "income\n",
      "<=50K    24553\n",
      ">50K      7823\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage distribution:\n",
      "income\n",
      "<=50K    75.84\n",
      ">50K     24.16\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final class distribution in training set:\n",
      "income\n",
      ">50K     50.0\n",
      "<=50K    50.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = main_classification_pipeline(df, target_column='income')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd08d6d5",
   "metadata": {},
   "source": [
    "### 4:\n",
    "Train classification models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ac5bf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "['>50K' '<=50K']\n",
      "int32\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "print(y_train.dtype)\n",
    "print(y_train.unique())\n",
    "\n",
    "# Needed because the target variable is an object type.\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test) \n",
    "print(y_train.dtype)\n",
    "print(y_test.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e90600",
   "metadata": {},
   "source": [
    "XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9b94dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(eval_metric='logloss')\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 8, None]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb_model, xgb_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "xgb_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_xgb_model = xgb_grid.best_estimator_\n",
    "print(\"Best XGBoost Parameters:\", xgb_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447b99ce",
   "metadata": {},
   "source": [
    "Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f91a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rf_model = \u001b[43mRandomForestClassifier\u001b[49m()\n\u001b[32m      2\u001b[39m rf_param_grid = {\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m100\u001b[39m, \u001b[32m200\u001b[39m, \u001b[32m300\u001b[39m],\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m5\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m15\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m      5\u001b[39m }\n\u001b[32m      7\u001b[39m rf_grid = GridSearchCV(rf_model, rf_param_grid, cv=\u001b[32m5\u001b[39m, scoring=\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15, None]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(rf_model, rf_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "rf_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_rf_model = rf_grid.best_estimator_\n",
    "print(\"Best Random Forest Parameters:\", rf_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfa5241",
   "metadata": {},
   "source": [
    "Catboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f05f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = CatBoostClassifier(verbose=0)\n",
    "cat_param_grid = {\n",
    "    'depth': [6, 10, 12],\n",
    "    'learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "cat_grid = GridSearchCV(cat_model, cat_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "cat_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_cat_model = cat_grid.best_estimator_\n",
    "print(\"Best CatBoost Parameters:\", cat_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e231b2",
   "metadata": {},
   "source": [
    "LGBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba91870",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = LGBMClassifier()\n",
    "lgbm_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "lgbm_grid = GridSearchCV(lgbm_model, lgbm_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "lgbm_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_lgbm_model = lgbm_grid.best_estimator_\n",
    "print(\"Best LightGBM Parameters:\", lgbm_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661d1666",
   "metadata": {},
   "source": [
    "TabPFN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabpfn_model = TabPFNClassifier(device='cuda' if torch.cuda.is_available() else 'cpu',ignore_pretraining_limits=True)\n",
    "\n",
    "# Fit on the smaller training set\n",
    "tabpfn_model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dcfc59",
   "metadata": {},
   "source": [
    "BernouliRBM which we didn't learn in class.\n",
    "* I used this documentation: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.BernoulliRBM.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159201da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing + RBM + LogisticRegression pipeline\n",
    "rbm_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),  # Optional but recommended\n",
    "    ('rbm', BernoulliRBM(random_state=42)),\n",
    "    ('log_reg', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "rbm_params = {\n",
    "    'rbm__n_components': [32, 64],\n",
    "    'log_reg__C': [0.1, 1.0]\n",
    "}\n",
    "\n",
    "# Create and run GridSearchCV\n",
    "rbm_grid = GridSearchCV(rbm_pipeline, rbm_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "rbm_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model and parameters\n",
    "best_rbm_model = rbm_grid.best_estimator_\n",
    "print(\"Best RBM + Logistic Regression Parameters:\", rbm_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e34a67d",
   "metadata": {},
   "source": [
    "### 5:\n",
    "Building a NN model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db919c10",
   "metadata": {},
   "source": [
    "I built a 3-layer feedforward NN with the following structure:\n",
    "* Dense layer - 64 neurons - with ReLu activation function - BatchNormalization (https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization) for faster convergence - and Dropout(0.3).\n",
    "* Dense - 32 neurons - ReLU - Dropout(0.2)\n",
    "* Dense - 1 neuron + Sigmoid (for 2-class classification ('income'))\n",
    "I chose this architecture in order to prevent overfitting using dropout and earlystopping, speed-up training using BatchNormalization, Ensure non linearity with ReLu.\n",
    "\n",
    "Related to my data I chose this architecture because my data is medium size and this architecture made the model optimized for binary classification and the feature space is not high dimensional after 'clean_categorical_columns' method so i try a simple and shallow version for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b566b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_shape=(X_train_scaled.shape[1],), activation='relu'),\n",
    "    BatchNormalization(trainable = False),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(1, activation='sigmoid')  # For binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af76c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12de4fe",
   "metadata": {},
   "source": [
    "### 6: \n",
    "Making Predictions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836854c9",
   "metadata": {},
   "source": [
    "A: Making Predicitons on the models I created before on train set and test set and print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3dfe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, is_nn=False):\n",
    "    print(f\"\\n📌 {name} – Train Performance:\")\n",
    "    y_train_pred = (model.predict(X_train) > 0.5).astype(int).flatten() if is_nn else model.predict(X_train) # CAN'T PRINT CLASSIFICATION REPORT ON CONTINOUS NUMBERS IN NN\n",
    "    print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "    print(f\"📌 {name} – Test Performance:\")\n",
    "    y_test_pred = (model.predict(X_test) > 0.5).astype(int).flatten() if is_nn else model.predict(X_test)\n",
    "    print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de9bfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\"XGBoost\", best_xgb_model, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a2252",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\"Random Forest\", best_rf_model, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a59f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\"Catboost\", best_cat_model, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a4d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\"LightGBM\", best_lgbm_model, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4fffb5",
   "metadata": {},
   "source": [
    "Due to computational limitations, TabPFN was evaluated on a 1000-sample subset. While this doesn't allow a fully fair comparison, it offers insight into TabPFN's performance characteristics on limited data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc23c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train_scaled[:1000]\n",
    "y_train_small = y_train[:1000]\n",
    "\n",
    "X_test_small = X_test_scaled[:1000]\n",
    "y_test_small = y_test[:1000]\n",
    "\n",
    "evaluate_model(\"TabPFN\", tabpfn_model, X_train_small, y_train_small, X_test_small, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0dcd3f",
   "metadata": {},
   "source": [
    "But I ran the evaluate_model in VS code on the original data (X_train_scaled, y_train, X_test_scaled, y_test) and I markdown the results to be consistent with answer 6.B + 6.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811241fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_model(\"TabPFN\", tabpfn_model, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f79d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\"BernouliRBM\", best_rbm_model, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e42158",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\"NN model\", model, X_train_scaled, y_train, X_test_scaled, y_test,is_nn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b7b0cd",
   "metadata": {},
   "source": [
    "B: Based on accuracy explain who is the best model, regard to train/test prediction, and use overfitting-underfitting terms:\n",
    "* Based on the accuracy metric, the best-performing model is the Neural network, which achieved 81% accuracy on the test set and 77% on the training set. The relatively small gap between the two sets suggests that the model does not suffer from overfitting or underfitting. Instead, it demonstrates good generalization closing to appropriate fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d68e61",
   "metadata": {},
   "source": [
    "C: Based on other metric explain who is the best model, regard to train/test prediction, explain the meaning of the metric and why does it relevant to this prediction task:\n",
    "* When considering the F1-score for class 1, the CatBoost model demonstrates the best performance, achieving an F1-score of 0.87 on the training set and 0.65 on the test set. The F1-score is the harmonic mean of precision and recall, and is especially valuable in classification tasks involving imbalanced datasets — like in our case, where the minority class (>50K) represents only about 24% of the data. \n",
    "if we wrongly predict a user as being the highest income group when he's not, it could lead to unfair decisions like offering services they don't qualify for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320a5762",
   "metadata": {},
   "source": [
    "### 7:\n",
    "A: Improving the NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb10baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_improved = Sequential([\n",
    "    Dense(128, input_shape=(X_train_scaled.shape[1],), activation='tanh'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(64, activation='tanh'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    Dense(32, activation='tanh'),\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_improved.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_improved.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_improved = model_improved.fit( \n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.3,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ae7635",
   "metadata": {},
   "source": [
    "Showing the differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c44dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\"Neural Network\", model, X_train_scaled, y_train, X_test_scaled, y_test,is_nn = True)\n",
    "evaluate_model(\"Enhanced Neural Network\", model_improved, X_train_scaled, y_train, X_test_scaled, y_test,is_nn = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31b7eeb",
   "metadata": {},
   "source": [
    "7.b:\n",
    "\n",
    "The original neural network already showed good performance, but several changes were made to improve generalization. The activation function was switched to tanh for smoother convergence, and the number of neurons and layers was increased to capture more complex patterns. Batch normalization was added for stability, dropout was reduced since overfitting wasn’t an issue, and the validation split was increased for better performance monitoring.  These modifications were aimed at pushing an already strong model to perform even better as reflected by the improved evaluation metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
